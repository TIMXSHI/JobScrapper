# .github/workflows/scrape-seek.yml
name: Scrape Seek (headed via Xvfb)

on:
  workflow_dispatch: {}
  schedule:
    - cron: "0 21 * * *"

permissions:
  contents: write

jobs:
  run-scraper:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies (Playwright + Chromium + Xvfb)
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          python -m playwright install --with-deps chromium
          sudo apt-get update
          sudo apt-get install -y xvfb

      - name: Run scraper under Xvfb (headed)
        env:
          HEADLESS: "false"
        run: |
          xvfb-run -a --server-args='-screen 0 1920x1080x24' python seek_scraper.py

      - name: Commit CSV back to repo
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          if [ -f "seek_jobs_24h.csv" ]; then
            git add seek_jobs_24h.csv
            git commit -m "Update seek_jobs_24h.csv [skip ci]" || echo "No changes to commit"
            git push
          else
            echo "⚠️ No CSV file generated by script"
            exit 1
          fi
